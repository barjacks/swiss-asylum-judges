{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the Textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import glob\n",
    "plt.style.use('ggplot')\n",
    "import dateutil.parser\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing list of file names to iterate through later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_list_of_names = []\n",
    "for name in glob.glob('txtfiles/*'):\n",
    "    name = name.split('/')[-1]\n",
    "    whole_list_of_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_list_of_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [the online database](http://www.bvger.ch/publiws/?lang=de) there are more cases mentioned than we anaylsed. This is due to duplicates in the database and merged cases. We used 'fdupes -dN .' on the command line to locate and remove 300 plus duplicate files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aktennummer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every expression is developed three times, as the verdicts are in three languages, French, German and Italian.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extracting_aktennummer_german(doc):\n",
    "    try:\n",
    "        entscheid = re.search(r'Abteilung [A-Z]+\\n[A-Z]-[0-9]+/[0-9]+', doc)\n",
    "        entscheid = entscheid.group()\n",
    "        entscheid = entscheid.replace('\\n', '')\n",
    "        return entscheid\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "def extracting_aktennummer_french(doc):\n",
    "    try:\n",
    "        entscheid = re.search(r'Cour [A-Z]+\\n[A-Z]-[0-9]+/[0-9]+', doc)\n",
    "        entscheid = entscheid.group()\n",
    "        entscheid = entscheid.replace('\\n', '')\n",
    "        return entscheid\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "def extracting_aktennummer_italian(doc):\n",
    "    try:\n",
    "        entscheid = re.search(r'Corte [A-Z]+\\n[A-Z]-[0-9]+/[0-9]+', doc)\n",
    "        entscheid = entscheid.group()\n",
    "        entscheid = entscheid.replace('\\n', '')\n",
    "        return entscheid\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entscheide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extracting_entscheid_italian(doc):\n",
    "    try:\n",
    "        doc = doc.replace('\\n1.  \\n', '')\n",
    "        doc = doc.replace('\\n1. \\n1.', '')\n",
    "        doc = doc.replace('\\n1.\\n1.', '')\n",
    "        entscheid = re.findall(r'Tribunale amministrativo federale pronuncia:\\n.*([^.]*)', doc)\n",
    "        entscheid = entscheid[0].replace('Oggetto', '').replace('\\n', '').strip()\n",
    "        entscheid = entscheid[:150]\n",
    "        return entscheid\n",
    "    except:\n",
    "        None\n",
    "\n",
    "def extracting_entscheid_french(doc):\n",
    "    try:\n",
    "        doc = doc.replace('\\n1.  \\n', '')\n",
    "        doc = doc.replace('\\n1. \\n1.', '')\n",
    "        doc = doc.replace('\\n1.\\n1.', '')\n",
    "        doc = doc.replace('\\n1.\\n\\n', '')\n",
    "        doc = doc.replace('\\n', '')\n",
    "        entscheid = re.findall(r'le Tribunal administratif fédéral prononce\\s*:1.([^.]*)', doc)\n",
    "        entscheid = entscheid[0].replace('Oggetto', '').replace('\\n', '').strip()\n",
    "        entscheid = entscheid[:150]\n",
    "        return entscheid\n",
    "    except:\n",
    "        None\n",
    "\n",
    "def extracting_entscheid_german(doc):\n",
    "    try:\n",
    "        #search_date = re.search(r'[0-9]+\\.', doc)\n",
    "        #search_date = search_date.group()\n",
    "        #doc = doc.replace(search_date, '')\n",
    "        doc = doc.replace('4.', '')\n",
    "        doc = doc.replace('6.', '')\n",
    "        doc = doc.replace('13.', '')\n",
    "        doc = doc.replace('8.', '')\n",
    "        doc = doc.replace('24.', '')\n",
    "        doc = doc.replace('25.', '')\n",
    "        doc = doc.replace('18.', '')\n",
    "        doc = doc.replace('30.', '')\n",
    "        doc = doc.replace('\\n1.  \\n', '')\n",
    "        doc = doc.replace('\\n1. \\n1.', '')\n",
    "        doc = doc.replace('\\n1.\\n1.', '')\n",
    "        entscheid = re.findall(r'erkennt das Bundesverwaltungsgericht\\s*:\\s*1.([^.]*)', doc)\n",
    "        entscheid = entscheid[0].replace('Oggetto', '').replace('\\n', '').strip()\n",
    "        entscheid = entscheid[:150]\n",
    "        return entscheid\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gegenstand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using findall, because the word might occur several times in the document. This way we can just take the first instance, making sure we are extracting correct term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extracting_gegenstand_italian(doc):\n",
    "    try:\n",
    "        gegenstand = re.findall(r'Oggetto.*([^,]*)', doc)\n",
    "        gegenstand = gegenstand[0].replace('Oggetto', '').replace('\\n', '').strip()\n",
    "        gegenstand = gegenstand[:84]\n",
    "        return gegenstand\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "def extracting_gegenstand_french(doc):\n",
    "    try:\n",
    "        gegenstand = re.findall(r'Objet.*([^,]*)', doc)\n",
    "        gegenstand = gegenstand[0].replace('Objet', '').replace('\\n', '').strip()\n",
    "        gegenstand = gegenstand[:84]\n",
    "        return gegenstand\n",
    "    except:\n",
    "        None\n",
    "\n",
    "def extracting_gegenstand_german(doc):\n",
    "    try:\n",
    "        gegenstand = re.findall(r'Gegenstand.*([^,]*)', doc)\n",
    "        gegenstand = gegenstand[0].replace('Gegenstand', '').replace('\\n', '').strip()\n",
    "        gegenstand = gegenstand[:84]\n",
    "        return gegenstand\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most important thing to keep in mind here is to use the various special characters from [French](http://unicode.e-workers.de/franzoesisch.php), [Italian](http://unicode.e-workers.de/italienisch.php) and German. Same here also applies findall usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extracting_date_french(doc):\n",
    "    Datum = re.findall(r\"Arrêt du [0-9]+[er]* [A-Z]*[éèàâæûa-z]+ 20[0-9]+\", doc)\n",
    "    try:\n",
    "        Datum = Datum[0]\n",
    "    except:\n",
    "        None\n",
    "    Datum = str(Datum).replace(\"['\", '').replace(\"']\", '').replace('Arrêt du', '').strip()\n",
    "    Datum = Datum.replace('1er', '1')\n",
    "    return Datum\n",
    "\n",
    "def extracting_date_german(doc):\n",
    "    Datum = re.findall(r\"Urteil vom [0-9]+.[ ]*[ÄÖÜA-Z][äüöa-z]+ 20[0-9]+\", doc)\n",
    "    try:\n",
    "        Datum = Datum[0]\n",
    "    except:\n",
    "        None\n",
    "    Datum = str(Datum).replace(\"['\", '').replace(\"']\", '').replace('Urteil vom ', '').strip()\n",
    "    Datum = Datum.replace(\".Ap\", '. Ap')\n",
    "    return Datum\n",
    "\n",
    "def extracting_date_italian(doc):\n",
    "    #\n",
    "    Datum = re.findall(r\"Sentenza del[l']*[ ]*[0-9]+[ |°][a-z]+ 20[0-9]+\", doc)\n",
    "    try:\n",
    "        Datum = Datum[0]\n",
    "    except:\n",
    "        None\n",
    "    Datum = str(Datum).replace(\"['\", '').replace(\"']\", '').replace('Sentenza del ', '').replace('°', ' ').strip()\n",
    "    Datum = Datum.replace(\"Sentenza dell'\", '')\n",
    "    return Datum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting list of judges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of judges was pulled of the [Website](http://www.bvger.ch/) with a separate scraper. This gave us the current judges. Judges from earlier years were research by hand from documentation in [Swiss parlament](https://www.parlament.ch/de/ratsbetrieb/amtliches-bulletin/amtliches-bulletin-erkl%C3%A4rt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_richter = pd.read_csv('data/richter_partei.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the list of judges with their party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relevant_clean_judges = list(df_richter['Nachname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the Lawyers and countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lawyers_countries(x):\n",
    "    avocat_countries = re.search('Parties\\n*.*\\n*.*', x)\n",
    "    anwalt_countries = re.search('Parteien\\n*.*\\n*.*', x)\n",
    "    avvocato_countries = re.search('Parti\\n*.*\\n*.*', x)\n",
    "    \n",
    "    try:\n",
    "        if anwalt_countries != None:\n",
    "            anwalt_countries = anwalt_countries.group()\n",
    "            x = x.replace(anwalt_countries, '|||')\n",
    "            return x\n",
    "        elif avocat_countries != None:\n",
    "            avocat_countries = avocat_countries.group()\n",
    "            x = x.replace(avocat_countries, '|||')\n",
    "            return text\n",
    "        elif avvocato_countries != None:\n",
    "            avvocato_countries = avvocato_countries.group()\n",
    "            x = x.replace(avvocato_countries, '|||')\n",
    "            return x\n",
    "        else:\n",
    "            return x\n",
    "    except:\n",
    "        None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the Gerichtsschreiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gerichtsschreiber(x):\n",
    "    \n",
    "    gerichtsschreiber = re.search(r'Gerichtsschreiber.*\\.', x)\n",
    "    gerichtsschreiberin = re.search(r'Gerichtsschreiberin.*\\n*', x)\n",
    "    cancelliera = re.search(r'cancellier.*,', x)\n",
    "    greffier = re.search(r'Greffier:.*', x)\n",
    "    \n",
    "    try:\n",
    "        if gerichtsschreiber != None:\n",
    "            gerichtsschreiber = gerichtsschreiber.group()\n",
    "            x = x.replace(gerichtsschreiber, '|||')\n",
    "            return x\n",
    "        elif gerichtsschreiberin != None:\n",
    "            gerichtsschreiberin = gerichtsschreiberin.group()\n",
    "            x = x.replace(gerichtsschreiberin, '|||')\n",
    "            return x\n",
    "        elif cancelliera != None:\n",
    "            cancelliera = cancelliera.group()\n",
    "            x = x.replace(cancelliera, '|||')\n",
    "            return x\n",
    "        elif greffier != None:\n",
    "            greffier = greffier.group()\n",
    "            x = x.replace(greffier, '|||')\n",
    "            return x\n",
    "        \n",
    "        for y in relevant_clean_judges:\n",
    "            y = y + ', greffi'\n",
    "            greffier = re.search(y, x)\n",
    "            if greffier != None:\n",
    "                greffier = greffier.group()\n",
    "                x = x.replace(greffier, '|||')\n",
    "            else:\n",
    "                return x\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating case list and judge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#searching for the relevant judges\n",
    "\n",
    "#Lists I already have\n",
    "#whole_list_of_names i my first list\n",
    "#relevant_clean_judges is my second list\n",
    "\n",
    "main_judge_list = []\n",
    "case_list = []\n",
    "vorsitz_list = []\n",
    "\n",
    "for file in whole_list_of_names: #medium_sample_list\n",
    "    \n",
    "    #Importing the texts\n",
    "    file_name = file\n",
    "    file = open('txtfiles/' + file, 'r')\n",
    "    text = file.read()\n",
    "    beginning = text[0:310]\n",
    "    end = text[-2000:]\n",
    "    end = end[0:1815]\n",
    "    text = beginning + end\n",
    "    \n",
    "    #Prepping text files\n",
    "    text = text.replace('E-4432/2006', 'E-4432/20 fsdfasdfaasdfasdfasdfasdfdasfasfasfasdfasfasfasdfsdfasdf')\n",
    "    text = text.replace(';', ',')\n",
    "    text = text.replace('\\n\\n', '\\n')\n",
    "    text = text.replace(':\\n1. Die', ':\\n1.\\nDie')\n",
    "    text = text.replace(':\\n1. Le', ':\\n1.\\nLe')\n",
    "    text = text.replace(':\\n1. Nella', ':\\n1.\\nNella')\n",
    "    text = text.replace('Demnach erkennt das Bundesverwaltungsgericht:             \\n1.\\n', 'Demnach erkennt das Bundesverwaltungsgericht:\\n1.\\n')\n",
    "    text = text.replace(':\\n1. Il', ':\\n1.\\nIl')\n",
    "    \n",
    "    #dealing with Gerichtsschreiber\n",
    "    text = gerichtsschreiber(text)\n",
    "    \n",
    "    #Pulling out lawyer's names, so they don't clash with judges names\n",
    "    text = lawyers_countries(text)\n",
    "    \n",
    "    #Makinging small judge name lists\n",
    "    short_judge_list = []\n",
    "    for judge in relevant_clean_judges:\n",
    "        \n",
    "        try:\n",
    "            judge = re.search(judge, text)\n",
    "            if judge != None:\n",
    "                judge = judge.group()\n",
    "                short_judge_list.append(judge)\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            None\n",
    "    \n",
    "    #Getting the date\n",
    "    if extracting_date_french(text) == '[]' and extracting_date_italian(text) == '[]':\n",
    "        date = extracting_date_german(text)\n",
    "    elif extracting_date_french(text) == '[]' and extracting_date_german(text) == '[]':\n",
    "        date = extracting_date_italian(text)\n",
    "    else:\n",
    "        date = extracting_date_french(text)\n",
    "    \n",
    "    #Getting Gegenstand\n",
    "    if extracting_gegenstand_german(text) == None and extracting_gegenstand_french(text) == None:\n",
    "        gegenstand = extracting_gegenstand_italian(text)\n",
    "        #print(file_name, gegenstand, date)\n",
    "    elif extracting_gegenstand_french(text) == None and extracting_gegenstand_italian(text) == None:\n",
    "        gegenstand = extracting_gegenstand_german(text)\n",
    "        #print(file_name, gegenstand, date)\n",
    "    else:\n",
    "        gegenstand = extracting_gegenstand_french(text)\n",
    "        #print(file_name, gegenstand, date)\n",
    "        \n",
    "    #Getting Entscheid\n",
    "    if extracting_entscheid_german(text) == None and extracting_entscheid_french(text) == None:\n",
    "        entscheid = extracting_entscheid_italian(text)\n",
    "        #print(file_name, entscheid, date)\n",
    "    elif extracting_entscheid_french(text) == None and extracting_entscheid_italian(text) == None:\n",
    "        entscheid = extracting_entscheid_german(text)\n",
    "        #print(file_name, entscheid, date)\n",
    "    else:\n",
    "        entscheid = extracting_entscheid_french(text)\n",
    "        #print(file_name, entscheid, date)\n",
    "        \n",
    "    #Getting Aktennummer\n",
    "    if extracting_aktennummer_german(text) == None and extracting_aktennummer_french(text) == None:\n",
    "        aktennummer = extracting_aktennummer_italian(text)\n",
    "        #print(file_name, aktennummer, date)\n",
    "    elif extracting_aktennummer_french(text) == None and extracting_aktennummer_italian(text) == None:\n",
    "        aktennummer = extracting_aktennummer_german(text)\n",
    "        #print(file_name, aktennummer, date)\n",
    "    else:\n",
    "        aktennummer = extracting_aktennummer_french(text)\n",
    "        #print(file_name, aktennummer, date)\n",
    "        \n",
    "    #Making small judge dictionaries\n",
    "    small_judge_list = []\n",
    "    \n",
    "    try:\n",
    "        for judge in short_judge_list:\n",
    "            jugdes_small_dicts = {'judge': judge,\n",
    "                              'date': date,\n",
    "                              'gegenstand': gegenstand,\n",
    "                              'decision': entscheid,\n",
    "                              'aktennummer': aktennummer,\n",
    "                              'myfile_number': file_name}\n",
    "            small_judge_list.append(jugdes_small_dicts)\n",
    "                \n",
    "    except:\n",
    "        None\n",
    "    \n",
    "        \n",
    "    #Making separate case file\n",
    "    small_case_list = []\n",
    "    try:\n",
    "        case_dict = {'date': date,\n",
    "                 'gegenstand': gegenstand,\n",
    "                 'decision': entscheid,\n",
    "                 'aktennummer': aktennummer,\n",
    "                 'myfile_number': file_name}\n",
    "        small_case_list.append(case_dict)\n",
    "    except:\n",
    "        None\n",
    "    \n",
    "    \n",
    "    case_list = case_list + small_case_list\n",
    "    main_judge_list = main_judge_list + small_judge_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DF out of the main judge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_judges = pd.DataFrame(main_judge_list)\n",
    "df_cases = pd.DataFrame(case_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'judge'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'judge'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ab5972595c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjugdes_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_judges\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'judge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'judge'"
     ]
    }
   ],
   "source": [
    "jugdes_count = df_judges['judge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "judges_count = pd.DataFrame(jugdes_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "judges_count.to_csv('jugdes_full_count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data. But we can't start analysing it just yet. We need to harmonise the various data points, i.e. dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First the dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting all the rows with no date. If there was a date, then the document wasn't a case file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_judges = df_judges[df_judges.date != '[]']\n",
    "df_cases = df_cases[df_cases.date != '[]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function, to harmonise all the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_harm(date):\n",
    "    #German\n",
    "    date = date.replace('. Januar ', '.1.')\n",
    "    date = date.replace('. Februar ', '.2.')\n",
    "    date = date.replace('. März ', '.3.')\n",
    "    date = date.replace('. April ', '.4.')\n",
    "    date = date.replace(' April ', '.4.')\n",
    "    date = date.replace('. Mai ', '.5.')\n",
    "    date = date.replace('. Juni ', '.6.')\n",
    "    date = date.replace('. Juli ', '.7.')\n",
    "    date = date.replace('. August ', '.8.')\n",
    "    date = date.replace('. September ', '.9.')\n",
    "    date = date.replace('. Oktober ', '.10.')\n",
    "    date = date.replace('. November ', '.11.')\n",
    "    date = date.replace('. Dezember ', '.12.')\n",
    "    #French\n",
    "    date = date.replace(' janvier ', '.1.')\n",
    "    date = date.replace(' février ', '.2.')\n",
    "    date = date.replace(' mars ', '.3.')\n",
    "    date = date.replace(' avril ', '.4.')\n",
    "    date = date.replace(' mai ', '.5.')\n",
    "    date = date.replace(' juin ', '.6.')\n",
    "    date = date.replace(' juillet ', '.7.')\n",
    "    date = date.replace(' août ', '.8.')\n",
    "    date = date.replace(' septembre ', '.9.')\n",
    "    date = date.replace(' octobre ', '.10.')\n",
    "    date = date.replace(' novembre ', '.11.')\n",
    "    date = date.replace(' décembre ', '.12.')\n",
    "    #Italian\n",
    "    date = date.replace(' gennaio ', '.1.')\n",
    "    date = date.replace(' febbraio ', '.2.')\n",
    "    date = date.replace(' marzo ', '.3.')\n",
    "    date = date.replace(' aprile ', '.4.')\n",
    "    date = date.replace(' maggio ', '.5.')\n",
    "    date = date.replace(' giugno ', '.6.')\n",
    "    date = date.replace(' luglio ', '.7.')\n",
    "    date = date.replace(' agosto ', '.8.')\n",
    "    date = date.replace(' settembre ', '.9.')\n",
    "    date = date.replace(' ottobre ', '.10.')\n",
    "    date = date.replace(' novembre ', '.11.')\n",
    "    date = date.replace(' dicembre ', '.12.')\n",
    "    \n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_judges['date_new'] = df_judges['date'].apply(date_harm)\n",
    "df_cases['date_new'] = df_cases['date'].apply(date_harm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Making the dates the index to map them out, only in the cases file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_date(str_date):\n",
    "    try:\n",
    "        return dateutil.parser.parse(str_date)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cases['date_new'] = df_cases['date_new'].apply(parse_date)\n",
    "df_judges['date_new'] = df_judges['date_new'].apply(parse_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cases.index = df_cases['date_new']\n",
    "df_judges.index = df_judges['date_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two dates were entered wrongly. Correcting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Correcting wrongly posted dates.\n",
    "df_cases['date_new']['2001-09-30'] = '2011-09-30'\n",
    "df_judges['date_new']['2001-09-30'] = '2011-09-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cases = df_cases.drop_duplicates(keep='first')\n",
    "df_judges = df_judges.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(10,5), facecolor='White')\n",
    "df_cases.resample('M')['aktennummer'].count().plot(ax=ax)\n",
    "ax.set_title(\"Urteile Bundesverwaltungsgericht 2007 - September 2016\", fontname='DIN Condensed', fontsize=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harmonising all the decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decision_harm_auto(x):\n",
    "    try: \n",
    "        gutgeheissen = re.search(r'utgeheissen', x)\n",
    "        gutgeheissen2 = re.search(r'utheissen', x)\n",
    "        gutgeheissen3 = re.search(r'gutzuheissen', x)\n",
    "        admis = re.search(r'admis', x)\n",
    "        accolto = re.search(r'ccolto', x)\n",
    "        accolta = re.search(r'ccolta', x)\n",
    "        joint = re.search(r'Les causes D-3901/2008, D-3902/2008, D-3903/2008, D-3904/2008 et D-3905/2008 sont jointes', x)\n",
    "        annulée = re.search(r'annulée', x)\n",
    "        aufgehoben = re.search('aufgehoben', x)\n",
    "        \n",
    "        nicht_eingetreten = re.search('nicht eingetreten', x)\n",
    "        abgeschrieben = re.search('abgeschrieben', x)\n",
    "        gegenstandslos_geworden = re.search('gegenstandslos geworden', x)\n",
    "        \n",
    "        abgewiesen = re.search(r'bgewiesen', x)\n",
    "        abgewiesen2 = re.search(r'abge-wiesen', x)\n",
    "        abgewiesen3 = re.search(r'abgwiesen', x)\n",
    "        rejeté = re.search(r'ejet', x)\n",
    "        respinto = re.search(r'espint', x)\n",
    "        \n",
    "        irrecevable = re.search(r'irrecevable', x)   \n",
    "         \n",
    "        #angenommen\n",
    "        if gutgeheissen != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif gutgeheissen2 != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif gutgeheissen3 != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif admis != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif accolto != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif accolta != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif aufgehoben != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif joint != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "        elif annulée != None:\n",
    "            x = 'Gutgeheissen'\n",
    "            return x\n",
    "             \n",
    "        #abgewiesen\n",
    "        elif abgewiesen != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif rejeté != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif respinto != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif irrecevable != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif nicht_eingetreten != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif abgewiesen2 != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif abgewiesen3 != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif abgeschrieben != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "        elif gegenstandslos_geworden != None:\n",
    "            x = 'Abgewiesen'\n",
    "            return x\n",
    "    \n",
    "        else:\n",
    "            return x\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cases['decision_harm_auto'] = df_cases['decision'].apply(decision_harm_auto)\n",
    "df_judges['decision_harm_auto'] = df_judges['decision'].apply(decision_harm_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of cases that weren't considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cases_non_harm_count = df_cases[df_cases['decision_harm_auto'] != 'Abgewiesen']\n",
    "df_cases_non_harm_count = df_cases_non_harm_count[df_cases_non_harm_count['decision_harm_auto'] != 'Gutgeheissen']\n",
    "Weitergezogen_oder_vereinigt = df_cases_non_harm_count['aktennummer'].count()\n",
    "Prozent_weitergezogen_etc = round((Weitergezogen_oder_vereinigt / df_cases['aktennummer'].count()) * 100, 1)\n",
    "Prozent_weitergezogen_etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Judge Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating new dfs with decision counts\n",
    "df_gutgeheissen = pd.DataFrame(df_judges[df_judges['decision_harm_auto'] == 'Gutgeheissen']['judge'].value_counts())\n",
    "df_gutgeheissen = df_gutgeheissen.reset_index()\n",
    "df_abgewiesen = pd.DataFrame(df_judges[df_judges['decision_harm_auto'] == 'Abgewiesen']['judge'].value_counts())\n",
    "df_abgewiesen = df_abgewiesen.reset_index()\n",
    "df_judge_quota = df_gutgeheissen.merge(df_abgewiesen, left_on='index', right_on='index')\n",
    "df_judge_quota.columns = [['judge', 'gutgeheissen', 'abgewiesen']]\n",
    "#del df_judge_quota['index']\n",
    "df_judge_quota['quota'] = round(df_judge_quota['gutgeheissen'] / (df_judge_quota['gutgeheissen'] + df_judge_quota['abgewiesen']) * 100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughest jugdes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing in the parties of the jugdges. This was scraped from the [BVGer site](http://www.bvger.ch/gericht/richter/index.html?lang=de). And gathered from [documentation from Swiss Parliament](https://www.parlament.ch/de/ratsbetrieb/amtliches-bulletin/amtliches-bulletin-erkl%C3%A4rt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_judge_partei = pd.read_csv('data/richter_partei.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_judge_quota = df_judge_quota.merge(df_judge_partei, left_on='judge', right_on='Nachname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_judge_quota[['judge', 'Partei', 'gutgeheissen', 'abgewiesen', 'quota']].sort_values(by='quota').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softest jugdes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_judge_quota[['judge', 'Partei', 'gutgeheissen', 'abgewiesen', 'quota']].sort_values(by='quota', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging with Richter Partei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_partei_vergleich = df_judges.merge(df_judge_partei, left_on='judge', right_on='Nachname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parteien-Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure all cells are stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_partei(x):\n",
    "    x = x.strip()\n",
    "    return x\n",
    "df_partei_vergleich['Partei'] = df_partei_vergleich['Partei'].apply(strip_partei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_partei_vergleich['Partei'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new dfs with decision counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_P_gutgeheissen = pd.DataFrame(df_partei_vergleich[df_partei_vergleich['decision_harm_auto'] == 'Gutgeheissen']['Partei'].value_counts())\n",
    "df_P_gutgeheissen = df_P_gutgeheissen.reset_index()\n",
    "df_P_abgewiesen = pd.DataFrame(df_partei_vergleich[df_partei_vergleich['decision_harm_auto'] == 'Abgewiesen']['Partei'].value_counts())\n",
    "df_P_abgewiesen = df_P_abgewiesen.reset_index()\n",
    "df_P_quota = df_P_gutgeheissen.merge(df_P_abgewiesen, left_on='index', right_on='index')\n",
    "df_P_quota.columns = [['judge', 'gutgeheissen', 'abgewiesen']]\n",
    "df_P_quota['quota in %'] = round(df_P_quota['gutgeheissen'] / (df_P_quota['gutgeheissen'] + df_P_quota['abgewiesen']) * 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_P_quota.sort_values(by='quota in %', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize =(10,5), facecolor='White')\n",
    "\n",
    "df_cases[df_cases['decision_harm_auto'] == 'Abgewiesen'].resample('M')['aktennummer'].count().plot(ax=ax)\n",
    "ax.set_title(\"Urteile Bundesverwaltungsgericht 2007 - , abgewiesene Klagen\", fontname='DIN Condensed', fontsize=24)\n",
    "\n",
    "df_cases[df_cases['decision_harm_auto'] == 'Gutgeheissen'].resample('M')['aktennummer'].count().plot(ax=ax)\n",
    "ax.set_title(\"Gutgeheissene vs Abgewiesene Urteile 2007 - 2016\", fontname='DIN Condensed', fontsize=24)\n",
    "\n",
    "plt.savefig('Gutgeheissene vs Abgewiesene Urteile 2007 - 2016.png', transparent=True, bbox_inches='tight')\n",
    "plt.savefig('Gutgeheissene vs Abgewiesene Urteile 2007 - 2016.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geschlechtervergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_w = df_partei_vergleich[df_partei_vergleich['Geschlecht'] == 'w']\n",
    "w_gutgeheissen = df_w[df_w['decision_harm_auto'] == 'Gutgeheissen']['aktennummer'].count()\n",
    "w_abgewiesen = df_w[df_w['decision_harm_auto'] == 'Abgewiesen']['aktennummer'].count()\n",
    "Prozent_w_gutgeheissen = w_gutgeheissen / (w_gutgeheissen + w_abgewiesen) * 100\n",
    "Prozent_w_gutgeheissen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_m = df_partei_vergleich[df_partei_vergleich['Geschlecht'] == 'm']\n",
    "m_gutgeheissen = df_m[df_m['decision_harm_auto'] == 'Gutgeheissen']['aktennummer'].count()\n",
    "m_abgewiesen = df_m[df_m['decision_harm_auto'] == 'Abgewiesen']['aktennummer'].count()\n",
    "Prozent_m_gutgeheissen = m_gutgeheissen / (m_gutgeheissen + m_abgewiesen) * 100\n",
    "Prozent_m_gutgeheissen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verlauf der einzelne Richter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#resample documentations: \n",
    "#http://stackoverflow.com/questions/17001389/pandas-resample-documentation\n",
    "df_Wenger = df_judges[df_judges['judge'] == 'Wenger']\n",
    "df_Wenger[df_Wenger['decision_harm_auto'] == 'Abgewiesen'].resample('Q')['aktennummer'].count().plot()\n",
    "df_Wenger[df_Wenger['decision_harm_auto'] == 'Gutgeheissen'].resample('Q')['aktennummer'].count().plot()\n",
    "plt.savefig('wenger.png', transparent=True, bbox_inches='tight')\n",
    "plt.savefig('wenger.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_haefeli = df_judges[df_judges['judge'] == 'Haefeli']\n",
    "df_haefeli[df_haefeli['decision_harm_auto'] == 'Abgewiesen'].resample('Q')['aktennummer'].count().plot()\n",
    "df_haefeli[df_haefeli['decision_harm_auto'] == 'Gutgeheissen'].resample('Q')['aktennummer'].count().plot()\n",
    "plt.savefig('haefeli.png', transparent=True, bbox_inches='tight')\n",
    "plt.savefig('haefeli.pdf', transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_theis = df_judges[df_judges['judge'] == 'Theis']\n",
    "df_theis[df_theis['decision_harm_auto'] == 'Abgewiesen'].resample('Q')['aktennummer'].count().plot()\n",
    "df_theis[df_theis['decision_harm_auto'] == 'Gutgeheissen'].resample('Q')['aktennummer'].count().plot()\n",
    "plt.savefig('theis.png', transparent=True, bbox_inches='tight')\n",
    "plt.savefig('theis.pdf', transparent=True, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
